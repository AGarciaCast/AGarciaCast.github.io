@InProceedings{pmlr-v285-garcia-castellanos24a,
  title = 	 {Relative Representations: Topological and Geometric Perspectives},
  author =       {Garc{\'i}a-Castellanos, Alejandro and Marchetti, Giovanni Luca and Kragic, Danica and Scolamiero, Martina},
  booktitle = 	 {Proceedings of UniReps: the Second Edition of the Workshop on Unifying Representations in Neural Models},
  pages = 	 {219--231},
  year = 	 {2024},
  editor = 	 {Fumero, Marco and Domine, Clementine and LÃ¤hner, Zorah and Crisostomi, Donato and Moschella, Luca and Stachenfeld, Kimberly},
  volume = 	 {285},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {14 Dec},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v285/main/assets/garcia-castellanos24a/garcia-castellanos24a.pdf},
  url = 	 {https://proceedings.mlr.press/v285/garcia-castellanos24a.html},
  abstract = 	 {Relative representations are an established approach to zero-shot model stitching, consisting of a non-trainable transformation of the latent space of a deep neural network. Based on insights of topological and geometric nature, we propose two improvements to relative representations. First, we introduce a normalization procedure in the relative transformation, resulting in invariance to non-isotropic rescalings and permutations. The latter coincides with the symmetries in parameter space induced by common activation functions. Second, we propose to deploy topological densification when fine-tuning relative representations, a topological regularization loss encouraging clustering within classes. We provide an empirical investigation on a natural language task, where both the proposed variations yield improved performance on zero-shot model stitching.}
}